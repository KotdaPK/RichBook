{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Layout Parsing\n",
    "\n",
    "In this tutorial, we will show how to use the `layoutparser` API to \n",
    "\n",
    "1. Load Deep Learning Layout Detection models and predict the layout of the paper image\n",
    "2. Use the coordinate system to parse the output \n",
    "\n",
    "The `paper-image` is from https://arxiv.org/abs/2004.08686."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.4\n"
     ]
    }
   ],
   "source": [
    "import layoutparser as lp\n",
    "import cv2\n",
    "print(lp.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Layout Models to detect complex layout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`layoutparser` can identify the layout of the given document with only 4 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./data/paper-image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(\"Failed to load image.\")\n",
    "else:\n",
    "    print(\"Image loaded successfully.\")\n",
    "\n",
    "image = image[..., ::-1] \n",
    "    # Convert the image from BGR (cv2 default loading style)\n",
    "    # to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final.pth?dl=1: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final.pth?dl=1: 330MB [00:25, 13.1MB/s]                               \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported query remaining: f{'dl': ['1']}, orginal filename: /home/kotda/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectron2LayoutModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlp://PubLayNet/faster_rcnn_R_50_FPN_3x/config\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL.ROI_HEADS.SCORE_THRESH_TEST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mList\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFigure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model = lp.models.Detectron2LayoutModel('lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config',\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#                                  extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#                                  label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\",4:\"Figure\"})\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Load the deep layout model from the layoutparser API \u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# For all the supported model, please check the Model \u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Zoo Page: https://layout-parser.readthedocs.io/en/latest/notes/modelzoo.html\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/models/detectron2/layoutmodel.py:119\u001b[0m, in \u001b[0;36mDetectron2LayoutModel.__init__\u001b[0;34m(self, config_path, model_path, label_map, extra_config, enforce_cpu, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_map \u001b[38;5;241m=\u001b[39m label_map\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/models/detectron2/layoutmodel.py:122\u001b[0m, in \u001b[0;36mDetectron2LayoutModel._create_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mdetectron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/engine/defaults.py:288\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    287\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m DetectionCheckpointer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 288\u001b[0m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mResizeShortestEdge(\n\u001b[1;32m    291\u001b[0m     [cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST, cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST], cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMAX_SIZE_TEST\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mFORMAT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/checkpoint/detection_checkpoint.py:62\u001b[0m, in \u001b[0;36mDetectionCheckpointer.load\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     path \u001b[38;5;241m=\u001b[39m parsed_url\u001b[38;5;241m.\u001b[39m_replace(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgeturl()  \u001b[38;5;66;03m# remove query from filename\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m---> 62\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_sync:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcasting model states from main worker ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fvcore/common/checkpoint.py:155\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, path, checkpointables)\u001b[0m\n\u001b[1;32m    152\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[0;32m--> 155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m incompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    158\u001b[0m     incompatible \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    159\u001b[0m ):  \u001b[38;5;66;03m# handle some existing subclasses that returns None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/checkpoint/detection_checkpoint.py:108\u001b[0m, in \u001b[0;36mDetectionCheckpointer._load_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    106\u001b[0m     loaded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching_heuristics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queries) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported query remaining: f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqueries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, orginal filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_url\u001b[38;5;241m.\u001b[39mgeturl()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported query remaining: f{'dl': ['1']}, orginal filename: /home/kotda/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1"
     ]
    }
   ],
   "source": [
    "model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', \n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})\n",
    "# model = lp.models.Detectron2LayoutModel('lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config',\n",
    "#                                  extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
    "#                                  label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\",4:\"Figure\"})\n",
    "    # Load the deep layout model from the layoutparser API \n",
    "    # For all the supported model, please check the Model \n",
    "    # Zoo Page: https://layout-parser.readthedocs.io/en/latest/notes/modelzoo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported query remaining: f{'dl': ['1']}, orginal filename: /home/kotda/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m extra_config \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL.ROI_HEADS.SCORE_THRESH_TEST\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.8\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize the model, which will download the files\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectron2LayoutModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define paths to the downloaded files\u001b[39;00m\n\u001b[1;32m     12\u001b[0m weights_file_with_query \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/models/detectron2/layoutmodel.py:119\u001b[0m, in \u001b[0;36mDetectron2LayoutModel.__init__\u001b[0;34m(self, config_path, model_path, label_map, extra_config, enforce_cpu, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_map \u001b[38;5;241m=\u001b[39m label_map\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/models/detectron2/layoutmodel.py:122\u001b[0m, in \u001b[0;36mDetectron2LayoutModel._create_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mdetectron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/engine/defaults.py:288\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    287\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m DetectionCheckpointer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 288\u001b[0m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mResizeShortestEdge(\n\u001b[1;32m    291\u001b[0m     [cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST, cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST], cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMAX_SIZE_TEST\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mFORMAT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/checkpoint/detection_checkpoint.py:62\u001b[0m, in \u001b[0;36mDetectionCheckpointer.load\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     path \u001b[38;5;241m=\u001b[39m parsed_url\u001b[38;5;241m.\u001b[39m_replace(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgeturl()  \u001b[38;5;66;03m# remove query from filename\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m---> 62\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_sync:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcasting model states from main worker ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fvcore/common/checkpoint.py:155\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, path, checkpointables)\u001b[0m\n\u001b[1;32m    152\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[0;32m--> 155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m incompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    158\u001b[0m     incompatible \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    159\u001b[0m ):  \u001b[38;5;66;03m# handle some existing subclasses that returns None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/detectron2/checkpoint/detection_checkpoint.py:108\u001b[0m, in \u001b[0;36mDetectionCheckpointer._load_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    106\u001b[0m     loaded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching_heuristics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queries) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported query remaining: f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqueries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, orginal filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_url\u001b[38;5;241m.\u001b[39mgeturl()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported query remaining: f{'dl': ['1']}, orginal filename: /home/kotda/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Model configuration and label map\n",
    "config_path = 'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config'\n",
    "label_map = {0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
    "extra_config = [\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8]\n",
    "\n",
    "# Initialize the model, which will download the files\n",
    "model = lp.Detectron2LayoutModel(config_path, extra_config=extra_config, label_map=label_map)\n",
    "\n",
    "# Define paths to the downloaded files\n",
    "weights_file_with_query = os.path.expanduser('~/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1')\n",
    "lock_file_with_query = os.path.expanduser('~/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth?dl=1.lock')\n",
    "\n",
    "# Define paths for renaming\n",
    "weights_file = os.path.expanduser('~/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth')\n",
    "lock_file = os.path.expanduser('~/.torch/iopath_cache/s/dgy9c10wykk4lq4/model_final.pth.lock')\n",
    "\n",
    "# Rename the files if they exist\n",
    "if os.path.exists(weights_file_with_query):\n",
    "    os.rename(weights_file_with_query, weights_file)\n",
    "\n",
    "if os.path.exists(lock_file_with_query):\n",
    "    os.rename(lock_file_with_query, lock_file)\n",
    "\n",
    "# Now reinitialize the model to use the renamed files\n",
    "model = lp.Detectron2LayoutModel(config_path, extra_config=extra_config, label_map=label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = model.detect(image)\n",
    "    # Detect the layout of the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(image, layout, box_width=3)\n",
    "    # Show the detected layout of the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the results from the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(layout)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `layout` variable is a `Layout` instance, which is inherited from list and supports handy methods for layout processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`layout` contains a series of `TextBlock`s. They store the coordinates in the `.block` variable and other information of the blocks like block type in `.type`, text in `.text`, etc. More information can be found at the [documentation](https://layout-parser.readthedocs.io/en/latest/api_doc/elements.html#layoutparser.elements.TextBlock). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the coordinate system to process the detected layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we filter text regions of specific type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blocks = lp.Layout([b for b in layout if b.type=='Text'])\n",
    "figure_blocks = lp.Layout([b for b in layout if b.type=='Figure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see below, the text recognized as section 5.2 will be dropped\n",
    "from our layout-recognized text regions as it is parsed as a TextBlock of\n",
    "type 'Title' as indicated by its different colored bounding box in the image\n",
    "above.\n",
    "\n",
    "As there could be text regions detected inside the figure region, we just drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blocks = lp.Layout([b for b in text_blocks \\\n",
    "                   if not any(b.is_in(b_fig) for b_fig in figure_blocks)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sort the text regions and assign ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "\n",
    "left_interval = lp.Interval(0, w/2*1.05, axis='x').put_on_canvas(image)\n",
    "\n",
    "left_blocks = text_blocks.filter_by(left_interval, center=True)\n",
    "left_blocks.sort(key = lambda b:b.coordinates[1], inplace=True)\n",
    "# The b.coordinates[1] corresponds to the y coordinate of the region\n",
    "# sort based on that can simulate the top-to-bottom reading order \n",
    "right_blocks = lp.Layout([b for b in text_blocks if b not in left_blocks])\n",
    "right_blocks.sort(key = lambda b:b.coordinates[1], inplace=True)\n",
    "\n",
    "# And finally combine the two lists and add the index\n",
    "text_blocks = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the cleaned text blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(image, text_blocks,\n",
    "            box_width=3, \n",
    "            show_element_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the text inside each text region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine with the OCR functionality in `layoutparser` to fetch the text in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_agent = lp.TesseractAgent(languages='eng') \n",
    "    # Initialize the tesseract ocr engine. You might need \n",
    "    # to install the OCR components in layoutparser:\n",
    "    # pip install layoutparser[ocr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in text_blocks:\n",
    "    segment_image = (block\n",
    "                       .pad(left=5, right=5, top=5, bottom=5)\n",
    "                       .crop_image(image))\n",
    "        # add padding in each image segment can help\n",
    "        # improve robustness \n",
    "        \n",
    "    text = ocr_agent.detect(segment_image)\n",
    "    block.set(text=text, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in text_blocks.get_texts():\n",
    "    print(txt, end='\\n---\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
